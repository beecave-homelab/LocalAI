services:
  api:
    image: localai/localai:latest-aio-gpu-hipblas
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - IMAGE_TYPE=extra
        - BASE_IMAGE=ubuntu:22.04
        - BUILD_TYPE=hipblas
        - GO_TAGS=tts
    container_name: localai
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 1m
      timeout: 20m
      retries: 5
    ports:
      - 8880:8080
    env_file:
      - .env
    environment:
      - DEBUG=true
      # - REBUILD=true # If your gpu is not already included in the current list of default targets the following build details are required.
      - BUILD_TYPE=hipblas
      - GPU_TARGETS=gfx1030 # Example for RX6600
      # - GPU_TARGETS=gfx1032
      - GO_TAGS=tts
      # - GO_TAGS="stablediffusion tts p2p"
      # - MODELS_PATH=/models
    volumes:
      - ./models:/build/models:cached
      - ./images/:/tmp/generated/images/
    devices:
      # AMD GPU only require the following devices be passed through to the container for offloading to occur.
      - /dev/dri
      - /dev/kfd
    group_add:
      - video
