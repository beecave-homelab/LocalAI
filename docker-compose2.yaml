services:
  api:
    image: localai/localai:latest-aio-gpu-hipblas
    build:
      context: .
      dockerfile: Dockerfile
      # args:
      #   - IMAGE_TYPE=extra
      #   - BASE_IMAGE=ubuntu:22.04
    container_name: localai
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 1m
      timeout: 20m
      retries: 5
    ports:
      - 8880:8080
    env_file:
      - .env
    environment:
      - DEBUG=true
      # If your gpu is not already included in the current list of default targets the following build details are required.
      # - REBUILD=true
      # - BUILD_TYPE=hipblas
      # - GPU_TARGETS=gfx1030 # Example for RX6600
      # - GO_TAGS="stablediffusion tts p2p"
      # - MODELS_PATH=./models
    volumes:
      #- /models:/build/models:cached
      - ./models:/build/models:cached
      - ./images/:/tmp/generated/images/
    devices:
      # AMD GPU only require the following devices be passed through to the container for offloading to occur.
      - /dev/dri
      - /dev/kfd
    # group_add:
      # - video
      # - render
